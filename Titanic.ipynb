{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "d66580d1-f255-86b9-e5c0-f012342ab8d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "train shape: (1047, 11) test shape: (262, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Hart, Mr. Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>394140</td>\n",
       "      <td>6.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Johnston, Master. William Arthur \"Willie\"</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Goodwin, Master. William Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 2144</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived                                       Name   Sex   Age  \\\n",
       "0       3         0                            Hart, Mr. Henry  male   NaN   \n",
       "1       3         0  Johnston, Master. William Arthur \"Willie\"  male   NaN   \n",
       "2       3         0         Goodwin, Master. William Frederick  male  11.0   \n",
       "\n",
       "   SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
       "0      0      0      394140   6.8583   NaN        Q  \n",
       "1      1      2  W./C. 6607  23.4500   NaN        S  \n",
       "2      5      2     CA 2144  46.9000   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NAVEEN KUMAR RAJENDRAN-1002039449\n",
    "#Machine Learning 6363 Assignment 3\n",
    "# some basic imports\n",
    "from scipy import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "from functools import partial\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#loading training dataset\n",
    "train = pd.read_csv('train.csv')\n",
    "#loading test dataset\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#displaying the shapes of the train and test data\n",
    "print(\"train shape: {} test shape: {}\".format(train.shape, test.shape))\n",
    "#top 3 elements of train\n",
    "train.head(3)\n",
    "\n",
    "#top 3 elements of test\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "72063fe1-8b92-850b-3ede-5e030c7429ae"
   },
   "outputs": [],
   "source": [
    "\n",
    "Train = train.copy() # Using 'copy()' allows to clone the dataset, creating a different object with the same values\n",
    "\n",
    "\n",
    "Titanic_data = [train, test]\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "train['Has_Cabin'] = train[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "test['Has_Cabin'] = test[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "for dataset in Titanic_data:\n",
    "    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "# Create new feature IsAlone from FamilySize\n",
    "for dataset in Titanic_data:\n",
    "    dataset['IsAlone'] = 0\n",
    "    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "# Remove all NULLS in the Embarked column\n",
    "for dataset in Titanic_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "# Remove all NULLS in the Fare column\n",
    "for dataset in Titanic_data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(train['Fare'].median())\n",
    "\n",
    "# Remove all NULLS in the Age column\n",
    "for dataset in Titanic_data:\n",
    "    Avg_age = dataset['Age'].mean()\n",
    "    st_age = dataset['Age'].std()\n",
    "    age_count = dataset['Age'].isnull().sum()\n",
    "    null_age = np.random.randint(Avg_age - st_age, Avg_age + st_age, size=age_count)\n",
    "    # Next line has been improved to avoid warning\n",
    "    dataset.loc[np.isnan(dataset['Age']), 'Age'] = null_age\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "\n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_srch = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_srch:\n",
    "        return title_srch.group(1)\n",
    "    return \"\"\n",
    "\n",
    "for dataset in Titanic_data:\n",
    "    dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "for dataset in Titanic_data:\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "for dataset in Titanic_data:\n",
    "    # Mapping Sex\n",
    "    dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "    \n",
    "    # Mapping titles\n",
    "    title_map = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
    "    dataset['Title'] = dataset['Title'].map(title_map)\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "    # Mapping Embarked\n",
    "    dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "    \n",
    "    # Mapping Fare\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] \t\t\t\t\t\t        = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "    \n",
    "    # Mapping Age\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "    dataset.loc[ dataset['Age'] > 64, 'Age'] ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "0486bde8-a09f-93c6-832d-c5c9760e2f6e"
   },
   "outputs": [],
   "source": [
    "drop_ele = ['Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "train = train.drop(drop_ele, axis = 1)\n",
    "test  = test.drop(drop_ele, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "abef639b-2b31-4209-20ef-d8ba15c4de74"
   },
   "source": [
    "## Visualization of  the  titanic dataset ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b587a7d3-36be-408e-0dee-6fd292e9621b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Survived  Sex  Age  Parch  Fare  Embarked  Has_Cabin  FamilySize  \\\n",
       "0       1         1    0    1      0     3         1          1           1   \n",
       "1       3         0    1    2      0     0         0          0           1   \n",
       "2       3         0    1    2      0     1         0          0           3   \n",
       "\n",
       "   IsAlone  Title  \n",
       "0        1      4  \n",
       "1        1      1  \n",
       "2        0      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "ce843f51-6f28-ef63-5f21-5f6bf8802e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1047, 10), test: (262, 10)\n",
      "train: (1047,), test: (262,)\n",
      "10\n",
      "1047\n"
     ]
    }
   ],
   "source": [
    "val = \"Survived\"\n",
    "#var variable is selected to be dropped from the table\n",
    "X = train.drop([val], axis=1)\n",
    "X_test = test.drop([val], axis=1)\n",
    "y = train[val]\n",
    "y_test = test[val]\n",
    "print(\"train: {}, test: {}\".format(X.shape, X_test.shape))\n",
    "print(\"train: {}, test: {}\".format(y.shape, y_test.shape))\n",
    "print((np.array(X)).shape[1])\n",
    "print((np.array(y)).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "05abd10a-b698-dc8a-f745-59436608e38c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individaul Survived: 0.387775, Individual Not Survivied: 0.612225\n"
     ]
    }
   ],
   "source": [
    "def accuracy(val_1, val_2):\n",
    "    #accuracy will be calculated as a sum when two values are equal and its divided my the length of the shape\n",
    "    acc = np.sum(val_1 == val_2) / val_1.shape[0]\n",
    "    return acc\n",
    "print(\"Individaul Survived: {:.6f}, Individual Not Survivied: {:.6f}\".format(y.sum()/len(y), 1-y.sum()/len(y)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Decision Tree \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for decision tree\n",
    "class DecisionTree:\n",
    "     #defining initialization for decision tree\n",
    "    def __init__(self, criterion,max_depth,min_samples_split,min_samples_leaf,sampl_featr=False):\n",
    "         #criterion for selecting  information_gain, gini_impurity\n",
    "        if criterion == 'entropy':\n",
    "            self.criterion = self._information_gain\n",
    "        elif criterion == 'gini':\n",
    "            self.criterion = self._gini_purification\n",
    "        else:\n",
    "            print('Criterion is ratio of gini or entropy')\n",
    "        self._tree, self.sampl_featr,self.min_samples_split,self.max_depth, self.min_samples_leaf = None, sampl_featr, max_depth, min_samples_leaf, min_samples_split\n",
    "        print(type(min_samples_leaf))\n",
    "        \n",
    "  # defining the fit method for the decision tree\n",
    "    def fit(self, X, y, smpl_wt=None):\n",
    "        if smpl_wt is None:\n",
    "            smpl_wt = np.ones(X.shape[0]) / X.shape[0]\n",
    "        else:\n",
    "            smpl_wt = np.array(smpl_wt) / np.sum(smpl_wt)\n",
    "\n",
    "        ftr_name, X, y = X.columns.tolist(), np.array(X), np.array(y)\n",
    "        self._tree = self._build_tree(X, y, ftr_name, depth=1, sample_weights=smpl_wt)\n",
    "        return self\n",
    "        \n",
    "   # defining entropy as static method \n",
    "    @staticmethod\n",
    "    def entropy(y, smpl_wt=None):\n",
    "        entrop, num = 0.0, y.shape[0]\n",
    "        lab_count={}\n",
    "        for i in range(num):\n",
    "            if y[i] not in lab_count.keys():\n",
    "                lab_count[y[i]]=0\n",
    "            lab_count[y[i]]+=smpl_wt[i]\n",
    "        for key in lab_count:\n",
    "            entrop-=float(lab_count[key])/float(np.sum(smpl_wt))*np.log2(float(lab_count[key])/float(np.sum(smpl_wt)))\n",
    "        return entrop\n",
    "\n",
    "  #defining information gain \n",
    "    def _information_gain(self, X, y, indx, smpl_wt=None):\n",
    "        info_gain, old_count, uni_val, new_count = 0, self.entropy(y, smpl_wt), np.unique(X[:,indx]), 0.0\n",
    "        for value in uni_val:\n",
    "            sub_X,sub_y, sub_smpl_wt=self._split_dataset(X, y, indx, value, smpl_wt)\n",
    "            prob=np.sum(sub_smpl_wt)/float(np.sum(smpl_wt))\n",
    "            new_count+=prob*self.entropy(sub_y, sub_smpl_wt)\n",
    "        info_gain=old_count-new_count \n",
    "        return info_gain\n",
    "\n",
    "   # defining gini_impurity as static method with labelcounts\n",
    "    @staticmethod\n",
    "    def gini_impurity(y, smpl_wt=None):\n",
    "        gini_i, num = 1, y.shape[0]\n",
    "        lab_count={}\n",
    "        for i in range(num):\n",
    "            if y[i] not in lab_count.keys():\n",
    "                lab_count[y[i]]=0\n",
    "            lab_count[y[i]]+=smpl_wt[i]\n",
    "        for key in lab_count:\n",
    "            gini_i -= (float(lab_count[key])/float(np.sum(smpl_wt))) ** 2\n",
    "        return gini_i\n",
    "\n",
    "  #defining gini_purification\n",
    "    def _gini_purification(self, X, y, indx, smpl_wt=None):\n",
    "        n_impurity, old_count, uni_val, new_count = 0, self.gini_impurity(y, smpl_wt), np.unique(X[:,indx]), 0.0\n",
    "        for value in uni_val:\n",
    "            sub_X,sub_y, sub_smpl_wt=self._split_dataset(X, y, indx, value, smpl_wt)\n",
    "            new_count+=np.sum(sub_smpl_wt)/float(np.sum(smpl_wt))*self.gini_impurity(sub_y, sub_smpl_wt)\n",
    "        n_impurity=old_count-new_count \n",
    "        return n_impurity\n",
    "\n",
    " #defining split dataset method\n",
    "    def _split_dataset(self, X, y, indx, val, smpl_wt=None):\n",
    "        rt, ft=[],X[:,indx]\n",
    "        X=X[:,[i for i in range(X.shape[1]) if i!=indx ]]\n",
    "        for i in range(len(ft)):\n",
    "            if ft[i]==val:\n",
    "                rt.append(i)\n",
    "        sub_X, sub_y, sub_smpl_wt = X[rt,:], y[rt], smpl_wt[rt]\n",
    "        return sub_X, sub_y, sub_smpl_wt\n",
    "\n",
    " #defining to choose best features\n",
    "    def _choose_best_feature(self, X, y, smpl_wt=None):\n",
    "        best_ftr_idx, n_ftr = 0, X.shape[1]\n",
    "        if self.sampl_featr:\n",
    "            max_ftr=max(1, min(n_ftr, int(np.round(np.sqrt(n_ftr)))))\n",
    "            new_ftr=np.random.choice(n_ftr, max_ftr, replace=False)\n",
    "            new_X=X[:, new_ftr]\n",
    "        else:\n",
    "            new_X=X\n",
    "        n_new_ftr, best_gain_ct=new_X.shape[1], 0.0\n",
    "        for i in range(n_new_ftr):\n",
    "            info_gain_ct=self.criterion(new_X,y,i,smpl_wt)           \n",
    "            if info_gain_ct > best_gain_ct:\n",
    "                best_gain_ct, best_ftr_idx=info_gain_ct, i          \n",
    "        return best_ftr_idx\n",
    "        \n",
    " #defining majority vote as static method\n",
    "    @staticmethod\n",
    "    def majority_vote(y, smpl_wt=None):\n",
    "        if smpl_wt is None:\n",
    "            smpl_wt = np.ones(y.shape[0]) / y.shape[0]\n",
    "        majority_lbl = y[0]\n",
    "        dict_num={}\n",
    "        for i in range(y.shape[0]):\n",
    "            if int(y[i]) not in dict_num.keys():\n",
    "                dict_num[y[i]]=smpl_wt[i]\n",
    "            else:\n",
    "                dict_num[y[i]] += smpl_wt[i]\n",
    "        return max(dict_num, key=dict_num.get)\n",
    "\n",
    " #defining build tree for construction of decision tree\n",
    "    # Update the _build_tree method\n",
    "    def _build_tree(self, X, y, ftr_names, depth, sample_weights=None):\n",
    "        mytree = dict()\n",
    "        if len(ftr_names) == 0 or len(np.unique(y)) == 1 or depth >= self.max_depth or len(X) <= self.min_samples_leaf:\n",
    "            return self.majority_vote(y, sample_weights)\n",
    "    \n",
    "        best_feature_idx = self._choose_best_feature(X, y, sample_weights)\n",
    "        best_feature_name = ftr_names[best_feature_idx]\n",
    "        ftr_names = ftr_names[:]\n",
    "        ftr_names.remove(best_feature_name)\n",
    "        mytree[best_feature_name] = {}\n",
    "        uniq_vals = np.unique(X[:, best_feature_idx])\n",
    "    \n",
    "        for value in uniq_vals:\n",
    "            sub_X, sub_y, sub_smpl_weights = self._split_dataset(X, y, best_feature_idx, value, sample_weights)\n",
    "            mytree[best_feature_name][value] = self._build_tree(sub_X, sub_y, ftr_names, depth + 1, sub_smpl_weights)\n",
    "    \n",
    "        return mytree\n",
    " #defining predict method for decision trees\n",
    "    def predict(self, X):\n",
    "        # Defining classify method\n",
    "        def _classify(tree, x):\n",
    "            if not isinstance(tree, dict):\n",
    "                return tree  \n",
    "\n",
    "            ftr_name = next(iter(tree))  \n",
    "            s_dict = tree[ftr_name]\n",
    "            key = x[ftr_name]  # Access the feature value from the input data\n",
    "\n",
    "            if key not in s_dict:\n",
    "                key = np.random.choice(list(s_dict.keys()))\n",
    "\n",
    "            valueOfKey = s_dict[key]\n",
    "\n",
    "            # Recursively call _classify for nested trees\n",
    "            return _classify(valueOfKey, x)\n",
    "\n",
    "        # Predicting the output for each sample in X\n",
    "        results = []\n",
    "        for i in range(X.shape[0]):\n",
    "            results.append(_classify(self._tree, X.iloc[i, :]))\n",
    "        return np.array(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model Implementation  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "012339ff-5353-268f-a97b-752aa4aa3602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "Accuracy of the train set: 0.8242597898758357\n",
      "Accuracy of the test set: 0.8091603053435115\n"
     ]
    }
   ],
   "source": [
    " # implementing model of decision tree by calling decision tree class\n",
    "dt = DecisionTree(criterion='gini', max_depth=4, min_samples_split=2,min_samples_leaf=4, sampl_featr=False)\n",
    "dt.fit(X, y)\n",
    "y_train_pred = dt.predict(X)\n",
    " # printing the accuracy of train of the model generated\n",
    "print(\"Accuracy of the train set: {}\".format(accuracy(y, y_train_pred)))\n",
    "# printing the accuracy of test for the model generated\n",
    "print(\"Accuracy of the test set: {}\".format(accuracy(y_test, dt.predict(X_test))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    " #defining class random forest\n",
    "class RandomForest:\n",
    "    def __init__(self, tree_learner,num_trees,min_features=2020):\n",
    "        np.random.seed(min_features)\n",
    "        self.num_trees, self.weak_learner= num_trees, tree_learner\n",
    "        self._estimators = [copy.deepcopy(self.weak_learner) for _ in range(self.num_trees)]\n",
    "\n",
    "  #defining function to get bootstrap dataset\n",
    "    def _get_bootstrap_dataset(self, X, y, i):\n",
    "        X_arr, y_arr=np.array(X), np.array(y)\n",
    "        idx=np.random.choice(X_arr.shape[0], X_arr.shape[0], replace=True)\n",
    "        X_bootstrap= X.iloc[idx, :]\n",
    "        y_bootstrap = y.iloc[idx]\n",
    "        self._estimators[i].fit(X_bootstrap, y_bootstrap)\n",
    "\n",
    "  #defining fit for random forest classifier\n",
    "    def fit(self, X, y):\n",
    "        self.labels, part_btstrap, pool=list(set(y)), partial(self._get_bootstrap_dataset, X, y), ThreadPool(self.num_trees)\n",
    "        pool.map(part_btstrap, list(range(self.num_trees)))\n",
    "        pool.close() and pool.join()\n",
    "        return self\n",
    "\n",
    "  # defining predict for random forest classifier \n",
    "    def predict(self, X):\n",
    "        N = X.shape[0]\n",
    "        y_pred = np.zeros(N)\n",
    "        preds=np.array([estimator.predict(X) for estimator in self._estimators])\n",
    "        pred_proba=np.array([(preds == label).mean(axis=0) for label in self.labels]).T\n",
    "        y_pred=np.array(self.labels)[np.argmax(pred_proba, axis=1)]\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "035b62df-00f6-ab53-7082-227051ff974e"
   },
   "source": [
    "## Random forest Model Implementation  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "Accuracy of the train set: 0.8089780324737345\n",
      "Accuracy of the test set: 0.8015267175572519\n"
     ]
    }
   ],
   "source": [
    "# implementing model for random forest\n",
    "base_learner = DecisionTree(criterion='gini', max_depth=2,min_samples_split=3, min_samples_leaf=4, sampl_featr=True)\n",
    "r = RandomForest(tree_learner=base_learner, num_trees=50, min_features=2020)\n",
    "r.fit(X, y)\n",
    "#predicting the training set\n",
    "y_train_pred = r.predict(X)\n",
    "# printing the accuracy of train for the model generated\n",
    "print(\"Accuracy of the train set: {}\".format(accuracy(y, y_train_pred)))\n",
    "# printing the accuracy of test for the model generated\n",
    "print(\"Accuracy of the test set: {}\".format(accuracy(y_test, r.predict(X_test))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing AdaBoost(BOOSTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # defining the boosting class\n",
    "class Adaboost:\n",
    "    # defining the initialization of method for boosting\n",
    "    def __init__(self,weak_learner,num_learner,learning_rate,min_features=2020):\n",
    "        np.random.seed(min_features)\n",
    "        self.learning_rate= learning_rate\n",
    "        self.weak_learner, self.num_learner = weak_learner, num_learner\n",
    "        self._estimators = [copy.deepcopy(self.weak_learner) \n",
    "                            for _ in range(self.num_learner)]\n",
    "        self._alphas = [1 \n",
    "                        for _ in range(num_learner)]\n",
    "    # Defining the fit method for boosting\n",
    "    def fit(self, X, y):\n",
    "        L = y.shape[0]\n",
    "        w = np.ones(L) / L\n",
    "        for i in range(self.num_learner):\n",
    "            self._estimators[i].fit(X, y, smpl_wt=w)\n",
    "            pred = self._estimators[i].predict(X)\n",
    "            error = np.sum((pred != y) * w)\n",
    "            alpha = 0.5 * np.log((1 - error) / max(error, 1e-10))\n",
    "            self._alphas[i] = alpha\n",
    "            w *= np.exp(-alpha * np.array(y) * pred) + 1e-4\n",
    "            w /= 2 * np.sqrt(error * (1 - error))\n",
    "        return self\n",
    "\n",
    "    # Implementing the predict method for Adaboost\n",
    "    def predict(self, X):\n",
    "        N = X.shape[0]\n",
    "        y_pred = np.zeros(N)\n",
    "        for i in range(self.num_learner):\n",
    "            y_pred += self._alphas[i] * self._estimators[i].predict(X)\n",
    "        return np.sign(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Model Implementation  ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n",
      "Accuracy of the train set: 0.8118433619866284\n",
      "Accuracy of the test set: 0.8129770992366412\n"
     ]
    }
   ],
   "source": [
    " # implementing the model for adabboost boosting classifier\n",
    "base_learner = DecisionTree(criterion='gini', max_depth=4,min_samples_split=2, min_samples_leaf=3, sampl_featr=False)\n",
    "ada = Adaboost(weak_learner= base_learner, num_learner=50,learning_rate=0.5, min_features=2020)\n",
    "ada.fit(X, y)\n",
    "#predicting the training set\n",
    "y_train_pred = ada.predict(X)\n",
    "# printing heaccuracy of train for the model generated\n",
    "print(\"Accuracy of the train set: {}\".format(accuracy(y, y_train_pred)))\n",
    "# printing the accuracy of test for the model generated\n",
    "print(\"Accuracy of the test set: {}\".format(accuracy(y_test, ada.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model performance of Decision tree\n",
      "\n",
      "Accuracy of the train set: 0.8118433619866284\n",
      "Accuracy of the test set: 0.8091603053435115\n",
      "\n",
      "The Model performance of Random Forest\n",
      "\n",
      "Accuracy of the train set: 0.8118433619866284\n",
      "Accuracy of the test set: 0.8015267175572519\n",
      "\n",
      "The Model performance of Boosting(ADAboost)\n",
      "\n",
      "Accuracy of the train set: 0.8118433619866284\n",
      "Accuracy of the test set: 0.8129770992366412\n"
     ]
    }
   ],
   "source": [
    "print('The Model performance of Decision tree\\n')\n",
    " # printing the accuracy of the model generated   \n",
    "print(\"Accuracy of the train set: {}\".format(accuracy(y, y_train_pred)))\n",
    " # printing the accuracy of the model generated   \n",
    "print(\"Accuracy of the test set: {}\".format(accuracy(y_test, dt.predict(X_test))))\n",
    "print('\\nThe Model performance of Random Forest\\n')\n",
    " # printing the accuracy of the model generated   \n",
    "print(\"Accuracy of the train set: {}\".format(accuracy(y, y_train_pred)))\n",
    " # printing the accuracy of the model generated   \n",
    "print(\"Accuracy of the test set: {}\".format(accuracy(y_test, r.predict(X_test))))\n",
    "print('\\nThe Model performance of Boosting(ADAboost)\\n')\n",
    " # printing the accuracy of the model generated   \n",
    "print(\"Accuracy of the train set: {}\".format(accuracy(y, y_train_pred)))\n",
    " # printing the accuracy of the model generated   \n",
    "print(\"Accuracy of the test set: {}\".format(accuracy(y_test, ada.predict(X_test))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On comparing the 3 models AdaBoost(Boosting) provides more Accuracy than the other 2 models decision tree and Random forest ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 3,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "886d5ead374c248a88e542b3362d4a2a699db30f125fd533335417ffeaaadd4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
